<!DOCTYPE html>

<html lang="ru">
<head>
<title>Эволюция экосистемы Java под интеграцию ИИ / Хабр</title>
</head>
<body>
<div id="mount"><div data-async-called="true" id="app"><div class="tm-layout__wrapper"><!--[--><!-- --><div></div><!-- --><header class="tm-header" data-test-id="header"><div class="tm-page-width"><!--[--><div class="tm-header__container"><!-- --><span class="tm-header__logo-wrap"><a class="tm-header__logo tm-header__logo_hl-ru tm-header__logo" href="/ru/"><svg class="tm-svg-img tm-header__icon" height="16" width="16"><title>Хабр</title><use xlink:href="/img/habr-logo-ru.svg#logo"></use></svg></a><span class="tm-header__beta-sign" style="display:none;">β</span></span><!--[--><div class="tm-dropdown tm-header__projects"><div class="tm-dropdown__head"><!--[--><button class="tm-header__dropdown-toggle"><svg class="tm-svg-img tm-header__icon tm-header__icon_dropdown" height="16" width="16"><title>Открыть список</title><use xlink:href="/img/megazord-v28.371b7fa3..svg#arrow-down"></use></svg></button><!--]--></div><!-- --></div><a class="tm-header__become-author-btn" href="/ru/sandbox/start/">Как стать автором</a><div class="tm-feature tm-feature tm-feature_variant-inline tm-header__feature"><!-- --></div><!-- --><!--]--><!-- --></div><!--]--></div></header><div class="tm-layout"><div class="tm-page-progress-bar"></div><div class="tm-base-layout__header_is-sticky tm-base-layout__header" data-menu-sticky="true"><div class="tm-page-width"><!--[--><div class="tm-base-layout__header-wrapper"><div class="tm-main-menu"><div class="tm-main-menu__section"><nav class="tm-main-menu__section-content"><!--[--><a class="tm-main-menu__item" data-test-id="main-menu-item" href="/ru/feed/">Моя лента</a><!--]--><!--[--><a class="tm-main-menu__item" href="/ru/articles/">Все потоки</a><!--]--><!--[--><!--[--><a class="tm-main-menu__item" data-test-id="main-menu-item" href="/ru/flows/develop/">Разработка</a><!--]--><!--[--><a class="tm-main-menu__item" data-test-id="main-menu-item" href="/ru/flows/admin/">Администрирование</a><!--]--><!--[--><a class="tm-main-menu__item" data-test-id="main-menu-item" href="/ru/flows/design/">Дизайн</a><!--]--><!--[--><a class="tm-main-menu__item" data-test-id="main-menu-item" href="/ru/flows/management/">Менеджмент</a><!--]--><!--[--><a class="tm-main-menu__item" data-test-id="main-menu-item" href="/ru/flows/marketing/">Маркетинг</a><!--]--><!--[--><a class="tm-main-menu__item" data-test-id="main-menu-item" href="/ru/flows/popsci/">Научпоп</a><!--]--><!--]--></nav></div></div><div class="tm-header-user-menu tm-base-layout__user-menu"><a class="tm-header-user-menu__item tm-header-user-menu__search" data-test-id="search-button" href="/ru/search/"><svg class="tm-svg-img tm-header-user-menu__icon tm-header-user-menu__icon_search tm-header-user-menu__icon_dark" height="24" width="24"><title>Поиск</title><use xlink:href="/img/megazord-v28.371b7fa3..svg#search"></use></svg></a><!-- --><!-- --><div class="tm-header-user-menu__item tm-header-user-menu__write"><div><svg class="tm-svg-img tm-header-user-menu__icon tm-header-user-menu__icon_write tm-header-user-menu__icon_dark" height="24" width="24"><title>Написать публикацию</title><use xlink:href="/img/megazord-v28.371b7fa3..svg#write"></use></svg></div><!-- --></div><!--[--><div class="tm-header-user-menu__item"><button class="tm-header-user-menu__toggle" data-test-id="user-menu-settings"><svg class="tm-svg-img tm-header-user-menu__icon tm-header-user-menu__icon_dark" height="24" width="24"><title>Настройки</title><use xlink:href="/img/megazord-v28.371b7fa3..svg#page-settings"></use></svg></button></div><a class="tm-header-user-menu__item" href="https://habr.com/kek/v1/auth/habrahabr/?back=/ru/companies/spring_aio/articles/883964/&amp;hl=ru" rel="nofollow"><!--[--><button class="btn btn_solid btn_small tm-header-user-menu__login" type="button"><!--[-->Войти<!--]--></button><!--]--></a><!--]--><!-- --><!--teleport start--><!--teleport end--><!-- --></div></div><!--]--></div></div><!-- --><div class="tm-page-width"><!--[--><!--]--></div><main class="tm-layout__container"><div class="tm-page" companyname="spring_aio" data-async-called="true" hl="ru" style="--0c809c5a:16px;--a086013e:100%;--7c457026:0;"><div class="tm-page-width"><!--[--><div class="tm-page__header"><!--[--><!--]--></div><div class="tm-page__wrapper"><div class="tm-page__main_has-sidebar tm-page__main"><div class="pull-down"><!-- --><div class="pull-down__header" style="height:0px;"><div class="pull-down__content" style="bottom:10px;"><svg class="tm-svg-img pull-down__icon pull-down__arrow" height="24" width="24"><title>Обновить</title><use xlink:href="/img/megazord-v28.371b7fa3..svg#pull-arrow"></use></svg></div></div><!--[--><!--[--><div class="tm-article-presenter"><!--[--><!--[--><!-- --><div class="tm-company-profile-card tm-company-article__profile-card"><div class="tm-company-card tm-company-profile-card__info"><div class="tm-company-card__header"><a class="tm-company-card__avatar" href="/ru/companies/spring_aio/profile/"><div class="tm-entity-image"><img alt="" class="tm-entity-image__pic" height="48" src="//habrastorage.org/getpro/habr/company/8f1/91a/458/8f191a4584b8fab12d15af23e447a1d5.png" width="48"/></div></a><!--[--><!-- --><div class="tm-counter-container tm-company-card__rating"><div class="tm-counter-container__header"><!--[--><!--[--><!--]--><div class="tm-votes-lever tm-votes-lever tm-votes-lever_appearance-rating"><!-- --><div class="tm-votes-lever__score tm-votes-lever__score_appearance-rating tm-votes-lever__score"><!--[--><span><span class="tm-votes-lever__score-counter tm-votes-lever__score-counter_rating tm-votes-lever__score-counter" data-test-id="votes-score-counter">77.73</span></span><!--]--></div><!-- --></div><!--]--></div><div class="tm-counter-container__footer"><!--[--><span class="tm-rating__text tm-rating__text">Рейтинг</span><!--]--></div></div><!-- --><!--]--></div><div class="tm-company-card__info"><a class="tm-company-card__name" href="/ru/companies/spring_aio/profile/"><span>Spring АйО</span></a><!-- --></div></div><div class="tm-company-profile-card__buttons"><div class="tm-button-follow tm-company-profile-card__button tm-company-profile-card__button_follow"><!-- --><button class="tm-button-follow__button tm-button-follow__button_big" data-test-id="follow-button" type="button">Подписаться</button></div><!-- --><!-- --><!-- --></div></div><!-- --><!--]--><!--]--><div class="tm-article-presenter__body" data-test-id="article-body"><div class="tm-misprint-area"><div class="tm-misprint-area__wrapper"><!--[--><article class="tm-article-presenter__content tm-article-presenter__content_narrow"><!--[--><div class="tm-article-presenter__header"><!--[--><!--]--><div class="tm-article-snippet tm-article-snippet tm-article-presenter__snippet"><!--[--><!--]--><div class="tm-article-snippet__meta-container"><div class="tm-article-snippet__meta"><span class="tm-user-info tm-article-snippet__author"><a class="tm-user-info__userpic" data-test-id="user-info-pic" href="/ru/users/spring_aio/" title="spring_aio"><div class="tm-entity-image"><img alt="" class="tm-entity-image__pic" height="24" src="//habrastorage.org/r/w48/getpro/habr/avatars/8e0/5e8/a1c/8e05e8a1c5fd4560f661efb2cb00e77e.png" width="24"/></div></a><span class="tm-user-info__user tm-user-info__user_appearance-default" data-test-id="user-info-description"><a class="tm-user-info__username" href="/ru/users/spring_aio/">spring_aio <!-- --></a><!--[--><span class="tm-article-datetime-published"><time datetime="2025-02-19T13:29:19.000Z" title="2025-02-19, 16:29">19  фев   в 16:29</time></span><!--]--></span></span></div><!-- --></div><h1 class="tm-title tm-title_h1" data-test-id="articleTitle" lang="ru"><span>Эволюция экосистемы Java под интеграцию ИИ</span></h1><div class="tm-article-snippet__stats" data-test-id="articleStats"><div class="tm-article-complexity tm-article-complexity_complexity-low"><span class="tm-svg-icon__wrapper tm-article-complexity__icon"><svg class="tm-svg-img tm-svg-icon" height="24" width="24"><title>Уровень сложности</title><use xlink:href="/img/megazord-v28.371b7fa3..svg#complexity-low"></use></svg></span><span class="tm-article-complexity__label">Простой</span></div><div class="tm-article-reading-time"><span class="tm-svg-icon__wrapper tm-article-reading-time__icon"><svg class="tm-svg-img tm-svg-icon" height="24" width="24"><title>Время на прочтение</title><use xlink:href="/img/megazord-v28.371b7fa3..svg#clock"></use></svg></span><span class="tm-article-reading-time__label">21 мин</span></div><span class="tm-icon-counter tm-data-icons__item"><svg class="tm-svg-img tm-icon-counter__icon" height="24" width="24"><title>Количество просмотров</title><use xlink:href="/img/megazord-v28.371b7fa3..svg#counter-views"></use></svg><span class="tm-icon-counter__value" title="4643">4.6K</span></span></div><div class="tm-publication-hubs__container" data-test-id="articleHubsList"><div class="tm-publication-hubs"><!--[--><span class="tm-publication-hub__link-container"><a class="tm-publication-hub__link" href="/ru/companies/spring_aio/articles/"><!--[--><span>Блог компании Spring АйО</span><!-- --><!--]--></a></span><span class="tm-publication-hub__link-container"><a class="tm-publication-hub__link" href="/ru/hubs/java/"><!--[--><span>Java</span><span class="tm-article-snippet__profiled-hub" title="Профильный хаб">*</span><!--]--></a></span><span class="tm-publication-hub__link-container"><a class="tm-publication-hub__link" href="/ru/hubs/kotlin/"><!--[--><span>Kotlin</span><span class="tm-article-snippet__profiled-hub" title="Профильный хаб">*</span><!--]--></a></span><span class="tm-publication-hub__link-container"><a class="tm-publication-hub__link" href="/ru/hubs/programming/"><!--[--><span>Программирование</span><span class="tm-article-snippet__profiled-hub" title="Профильный хаб">*</span><!--]--></a></span><!--]--></div></div><div class="tm-article-labels" data-test-id="articleLabels"><div class="tm-article-labels__container"><div class="tm-publication-label tm-publication-label_variant-review"><span>Обзор</span></div><!--[--><div class="tm-publication-label tm-publication-label_variant-translation"><span>Перевод</span></div><!--]--></div></div><!-- --><!-- --></div></div><!--[--><div class="tm-article-presenter__origin"><a class="tm-article-presenter__origin-link" href="https://inside.java/2025/01/29/evolution-of-java-ecosystem-for-integrating-ai/" target="_blank">Автор оригинала: <span>Poonam Parhar</span></a></div><div class="tm-article-body" data-gallery-root="" lang="ru"><div><!--[--><!--]--></div><div id="post-content-body"><div><div class="article-formatted-body article-formatted-body article-formatted-body_version-2"><div xmlns="http://www.w3.org/1999/xhtml"><p>Новый перевод от команды<a href="https://t.me/+QmrKn0wA8CdkNjAy"> Spring АйО</a> расскажет вам, как новые библиотеки и фреймворки расширяют экосистему Java, делая возможной интеграцию ИИ-решений в приложения, написанные на Java. </p><p>Статья также включает в себя туториал, рассказывающий по шагам, как написать простой помощник по отладке приложений на Java, используя возможности больших языковых моделей.</p><hr/><p>Generative AI, в особенности большие языковые модели  (Large Language Models — LLMs) привлекли значительное внимание к своей способности создавать новый контент и расширять пользовательский опыт через обработку естественного языка, став новым приоритетом для предпринимателей, желающих обогатить свои приложения возможностями ИИ. По мере того, как искусственный интеллект (ИИ) становится движущей силой для технических инноваций, экосистема Java быстро эволюционирует под требования ИИ решений. </p><p>Появилось несколько фреймворков и библиотек для работы с ИИ, некоторые из них open source, стимулируя разработчиков интегрировать функционал, основанный на ИИ. Более того, Enterprise решения, такие как Generative AI от Oracle, расширяют набор возможностей ИИ, доступный для Java приложений и облачных окружений.</p><p>В этой статье мы посмотрим на известные библиотеки и фреймворки для встраивания функционала generative AI в приложения Java, такие как <code>LangChain4j</code>, <code>Spring AI</code> и <code>Jlama</code>, а также на Enterprise решения, в частности, Generative AI от Oracle. Вооружившись этим знанием, мы разработаем чатбот, способный поддерживать диалог, используя сервис Generative AI от Oracle и его Java SDK, а затем повысим точность его ответов, добавив больше возможностей от <code>LangChain4j</code>.</p><h3>LangChain4J </h3><div class="floating-image"><figure class="float"><img data-src="https://habrastorage.org/getpro/habr/upload_files/cc0/3a4/861/cc03a486117d162ad1ac3458cc89f75f.png" height="300" src="https://habrastorage.org/r/w1560/getpro/habr/upload_files/cc0/3a4/861/cc03a486117d162ad1ac3458cc89f75f.png" width="300"/></figure><p></p></div><p><a href="https://github.com/langchain4j/langchain4j">LangChain4j</a> — это Java библиотека, созданная для упрощения интеграции больших языковых моделей (Large Language Models, LLMs) в приложения на Java. Проект начал развиваться в 2023 на фоне растущей эйфории по поводу ChatGPT. Создатели <code>LangChain4j</code> обратили внимание на отсутствие — на тот момент — альтернатив на Java растущему количеству LLM библиотек и фреймворков для Python и JavaScript. Этот пробел в экосистеме Java натолкнул их на мысль о разработке <code>LangChain4j</code> в качестве решения этой проблемы.</p><details class="spoiler"><summary>Комментарий от редакции Spring АйО</summary><div class="spoiler__content"><p> На момент перевода статьи, Spring AI, как модуль для работы с AI в экосистеме Spring, не имеет GA (Generally Available) релиза. </p></div></details><p><code>LangChain4j</code> быстро заслужила внимание и признание в сообществе Java, примерно за полтора года, особенно среди разработчиков, работающих над приложениями на основе LLM. Библиотека активно развивается, новые возможности и интеграции добавляются регулярно. </p><p><code>LangChain4j</code> предлагает <a href="https://docs.langchain4j.dev/intro">ключевые возможности</a>, которые превращают ее в мощную библиотеку для интеграции больших языковых моделей в приложения на Java. Она предоставляет <strong>Унифицированный API</strong> для доступа к разным провайдерам LLM, моделям и хранилищам эмбеддингов, позволяя разработчикам легко переключаться между разными моделями LLM и хранилищами эмбеддингов, не переписывая код. Она также предлагает широкий диапазон <strong>инструментов и абстракций</strong>, специально созданных для работы с LLMs.</p><details class="spoiler"><summary>Комментарий от редакции Spring АйО</summary><div class="spoiler__content"><p> Под "хранлищами эмбеддингов" идёт речь речь о векторных базах данных, таких как ChromaDB, например. </p></div></details><p>Ее унифицированный API дает возможность интегрироваться с большим количеством LLM провайдеров и их моделями, включая серийные модели GPT-3.5 и GPT-4 от OpenAI, Gemini от Google, Claude от Anthropic, модели Cohere, локальные модели и различные модели open-source, находящиеся на хостинге Hugging Face. Она также поддерживает модели эмбеддингов и хранилища векторных представлений, число которых постоянно растет. </p><p>Многофункциональный набор инструментов от LangChain4j включает в себя <em>Prompt Templates</em>, что облегчает создание динамических промптов через задание структуры промптов, которые позволяют заполнять некоторые значения в рантайме. Библиотека предлагает инструменты <em>Chat Memory Management</em>, которые позволяют хранить и извлекать историю взаимодействия с пользователем, что очень важно при создании агентов-собеседников.  <em>Tools </em>внутри API позволяют вызывать функции и выполнять динамически сгенерированный код языковыми моделями. <code>LangChain4j</code> также предоставляет инструменты для генерации с использованием RAG (Retrieval-Augmented Generation), включая загрузчики документов, сплиттеры и механизмы извлечения. Более того, она предлагает <code>AI Services (high-level API)</code>, который позволяет уйти от чрезмерной сложности работы с LLMs через абстракции, давая разработчикам возможность взаимодействовать с языковыми моделями через простые интерфейсы Java. </p><p><code>LangChain4j</code> поддерживает интеграцию с моделями текстов и графики, позволяя разрабатывать более гибкие приложения на ИИ. Она также хорошо интегрируется с популярными Java фреймворками, такими как Spring Boot и Quarkus, благодаря чему становится проще встраивать этот функционал в существующие проекты Java. </p><h3>Spring AI</h3><div class="floating-image"><figure class="float"><img data-src="https://habrastorage.org/getpro/habr/upload_files/5e5/871/e97/5e5871e97e638450d4ad3eb40b4bfb1b.png" height="225" src="https://habrastorage.org/r/w1560/getpro/habr/upload_files/5e5/871/e97/5e5871e97e638450d4ad3eb40b4bfb1b.png" width="225"/></figure><p></p></div><p><a href="https://spring.io/projects/spring-ai">Spring AI</a> — это еще один популярный фреймворк, интегрирующий ИИ в Java. Это расширение <a href="https://spring.io/projects">экосистемы</a> Spring, специально созданной для того, чтобы помочь Enterprise приложениям интегрироваться с моделями ИИ. Он поддерживает все основные <a href="https://docs.spring.io/spring-ai/reference/api/index.html">провайдеры ИИ моделей</a> и предлагает поддержку на уровне API для всех этих провайдеров. Он также поддерживает векторные базы данных и абстракцию моделей, что упрощает переключение между различными моделями ИИ. Его API позволяет моделям запрашивать вызов <a href="https://docs.spring.io/spring-ai/reference/api/functions.html">инструментов и функций</a> со стороны клиента, позволяя модели выполнять задачи динамически. <code>Spring AI</code> хорошо интегрируется с существующими приложениями на Spring, благодаря чему он стал отличным решением для Enterprise окружений, которые уже опираются на экосистему Spring. </p><h3>Jlama </h3><div class="floating-image"><figure class="float"><img data-src="https://habrastorage.org/getpro/habr/upload_files/623/4fd/702/6234fd7020e13377a6e7578cc5824f4a.png" height="295" src="https://habrastorage.org/r/w1560/getpro/habr/upload_files/623/4fd/702/6234fd7020e13377a6e7578cc5824f4a.png" width="297"/></figure><p></p></div><p><a href="https://github.com/tjake/Jlama/blob/main/README.md">Jlama</a> предлагает  нативный движок для работы с LLM прямо из Java приложения. Если вы хотите запускать большие языковые модели локально и эффективно внутри окружения Java, <code>Jlama</code> выглядит, как идеальное решение. <code>Jlama</code> полностью построена на Java, используя библиотеки и API на Java для всех LLM операций. Она облегчает локальное выполнение модели внутри виртуальной машины Java (JVM). </p><details class="spoiler"><summary>Комментарий от редакции Spring АйО</summary><div class="spoiler__content"><p> Да, на самом деле так и происходит. Модель бежит прямо в рамках виртуальной машины. Но, конечно, надо понимать, что языковые модели, как правило, довольно большие сами по себе и могут занимать довольно большое количество ресурсов при своей работе. Для решения подобной проблемы используют Квантизацию (иногда говорят "Квантование") языковых моделей, но это другая история. </p></div></details><p>Таким образом убирается необходимость использования удаленных API  или облачных сервисов для работы с AI, что делает <code>Jlama</code> подходящим решением для use case-ов, которые требуют защиты данных, низкой latency или возможности работать оффлайн. Она использует preview Vector API для более быстрого вывода, что требует Java 20 или более поздних версий. </p><details class="spoiler"><summary>Комментарий от редакции Spring АйО</summary><div class="spoiler__content"><p> Речь про Preview API для работы с векторными инструкциями CPU, подробнее можно почитать в рамках JEP 448 </p></div></details><p>Кроме того, она поддерживает <a href="https://huggingface.co/tjake">квантизированные</a> модели, значительно снижая использование локальной памяти и время вывода. </p><h3>Сервис Oracle Generative AI</h3><p><a href="https://docs.oracle.com/en-us/iaas/Content/generative-ai/home.htm">Oracle Generative AI</a> — это управляемый сервис Oracle Cloud Infrastructure (OCI), предоставляющий набор кастомизируемых больших языковых моделей (LLMs), покрывающих широкий набор use case-ов, включая чаты, генерацию текста, обзор содержимого и создание текстовых эмбеддингов. Более того, он также предлагает <a href="https://docs.oracle.com/en-us/iaas/Content/API/SDKDocs/javasdk.htm#SDK_for_Java"> SDK для Java</a> для интеграции моделей generative AI в приложения на Java. Чтобы получить доступ и установить SDK для Java, <a href="https://docs.oracle.com/en-us/iaas/Content/API/SDKDocs/javasdkgettingstarted.htm">перейдите по этой ссылке</a>.</p><blockquote><p>Отметим, что для доступа к любому OCI сервису необходим аккаунт в Oracle Cloud Infrastructure. Перейдите по этой <a href="https://www.oracle.com/cloud/free/">ссылке</a>, чтобы узнать больше о бесплатном пакете и создать собственный аккаунт. </p></blockquote><p>Более того, сервис OCI Generative AI предлагает ряд больших языковых моделей для универсального чата. </p><figure class="full-width"><img alt="Рисунок 1: OCI модели чатов  " data-src="https://habrastorage.org/getpro/habr/upload_files/963/86c/2a6/96386c2a6c012d1a74391e329591f600.png" height="460" src="https://habrastorage.org/r/w1560/getpro/habr/upload_files/963/86c/2a6/96386c2a6c012d1a74391e329591f600.png" title="Рисунок 1: OCI модели чатов  " width="1159"/><div><figcaption>Рисунок 1: OCI модели чатов  </figcaption></div></figure><p>Теперь, когда мы знаем, что существует популярная опция для работы с Java и generative AI, давайте изучим ее получше, написав простую программу, которая создает чат-бот командной строки, поддерживаемый LLM моделью от сервиса OCI Generative AI.</p><h3>Создание чат-бота в Java с использованием OCI Generative AI</h3><p>Мы разработаем чат-бот, используя OCI SDK для Java, и позволим пользователям вступить с ним в разговор. </p><figure class="full-width"><img alt="Рисунок 2: Чат-бот, использующий OCI SDK для Java " data-src="https://habrastorage.org/getpro/habr/upload_files/a36/02b/6c3/a3602b6c324066760d4e0ddb0c07ac93.png" height="285" src="https://habrastorage.org/r/w1560/getpro/habr/upload_files/a36/02b/6c3/a3602b6c324066760d4e0ddb0c07ac93.png" title="Рисунок 2: Чат-бот, использующий OCI SDK для Java " width="882"/><div><figcaption>Рисунок 2: Чат-бот, использующий OCI SDK для Java </figcaption></div></figure><p>Работать над этим примером мы начнем с проекта на Java с Maven. Вы можете воспользоваться своей любимой IDE, чтобы сгенерировать базовый <code>pom.xml</code> и структуру каталогов по умолчанию для Maven-проекта с заданным каталогом для исходников. Файл <code>pom.xml</code> — это единый конфигурационный файл, содержащий большую часть информации, необходимой для создания проекта. </p><p>Затем мы кастомизируем pom файл, добавив в него следующие зависимости, чтобы получить доступ к OCI SDK для Java.</p><pre><code class="xml">	&lt;dependency&gt;
    		&lt;groupId&gt;com.oracle.oci.sdk&lt;/groupId&gt;
    		&lt;artifactId&gt;oci-java-sdk-common&lt;/artifactId&gt;
    		&lt;version&gt;3.55.1&lt;/version&gt;
	&lt;/dependency&gt;
	&lt;dependency&gt;
    		&lt;groupId&gt;com.oracle.oci.sdk&lt;/groupId&gt;
&lt;artifactId&gt;oci-java-sdk-common-httpclient-jersey&lt;/artifactId&gt;
    		&lt;version&gt;3.55.1&lt;/version&gt;
	&lt;/dependency&gt;
	&lt;dependency&gt;
    		&lt;groupId&gt;com.oracle.oci.sdk&lt;/groupId&gt;
&lt;artifactId&gt;oci-java-sdk-generativeaiinference&lt;/artifactId&gt;
    		&lt;version&gt;3.55.1&lt;/version&gt;
	&lt;/dependency&gt;</code></pre><p>Библиотека <code>oci-java-sdk-common</code> является центральным модулем OCI Java SDK. Она предоставляет важные утилиты, разделенные конфигурации и фундаментальные компоненты для приложений на Java, чтобы они могли эффективно взаимодействовать с OCI сервисами. Модуль <code>oci-java-sdk-common-httpclient-jersey</code> предоставляет функциональность, которая фокусируется на взаимодействии с HTTP клиентами, используя фреймворк Jersey. И, наконец, модуль <code>oci-java-sdk-generativeaiinference</code> поддерживает взаимодействие с сервисом OCI Generative AI.</p><p>Чтобы использовать OCI SDK, мы прежде всего должны <a href="https://docs.oracle.com/en-us/iaas/Content/API/Concepts/sdk_authentication_methods.htm">аутентифицироваться</a>. Самый простой способ это сделать — это воспользоваться интерфейсом командной строки Oracle Cloud Infrastructure (OCI), <code>oci</code>, который можно инсталлировать, воспользовавшись <a href="https://docs.oracle.com/en-us/iaas/Content/API/SDKDocs/cliinstall.htm">этими инструкциями</a>. Далее, следуем инструкциям, чтобы <a href="https://docs.oracle.com/en-us/iaas/Content/API/SDKDocs/cliinstall.htm#configfile">настроить конфигурационный файл</a>. После прохождения всех этих шагов мы получим файл <code>config</code>, чье местоположение зависит от вашей операционной системы, например, в окружениях семейства Unix он будет находиться по адресу <code>~/.oci/config</code>.</p><p>Как только мы получили файл <code>config</code>, мы можем предоставить эту локацию нашему приложению чат-бота и настроить для него доступ к OCI, включая эндпоинт для generative AI, детали конфигурации и compartment ID. В дальнейшем вы можете использовать информацию о местоположении файла <code>config</code> при настройке класса <code>OCIGenAIEnv</code>, пример которого приведен ниже, чтобы хранить настройки конфигурации, специфичные для окружения, для сервиса Oracle Cloud Infrastructure (OCI) Generative AI.</p><pre><code class="java">public class OCIGenAIEnv {
    // The OCI Generative AI service is available in several regions.
    // https://docs.oracle.com/en-us/iaas/Content/generative-ai/overview.htm#regions
    // Here, we use the Generative AI service endpoint in Chicago region.
    private static final String ENDPOINT = "https://inference.generativeai.us-chicago-1.oci.oraclecloud.com";

    // location of the OCI configuration file
    private static final String CONFIG_LOCATION = "~/.oci/config";

    // profile name within the OCI configuration file to use
    private static final String CONFIG_PROFILE = "DEFAULT";

    // unique identifier of the compartment that has the policies granting
    // permissions for using the Generative AI Service. See how to set policies:
    // https://docs.oracle.com/en-us/iaas/Content/generative-ai/iam-policies.htm
    private static final String COMPARTMENT_ID = "ocid1.compartment.oc1..xxx";
}</code></pre><blockquote><p>Чтобы Compartment ID хранился безопасно, установите <code>COMPARTMENT_ID</code> как переменную окружения и получайте к ней доступ через <code>System.getenv("COMPARTMENT_ID")</code>. Хардкодить ее не надо. </p></blockquote><p>Следующим шагом мы обеспечиваем безопасные коммуникации с сервисами OCI, инстанциируя <code>AuthenticationDetailsProvider</code> с константами <code>OCIGenAIEnv</code>. Затем мы используем провайдер для создания <code>GenerativeAiInferenceClient</code>, который упрощает взаимодействие с языковой моделью OCI. </p><pre><code class="java">    // read configuration details from the config file and create an AuthenticationDetailsProvider
    ConfigFileReader.ConfigFile configFile;
    AuthenticationDetailsProvider provider;
    try {
        configFile = ConfigFileReader.parse(OCIGenAIEnv.getConfigLocation(), OCIGenAIEnv.getConfigProfile());
        provider = new ConfigFileAuthenticationDetailsProvider(configFile);
    } catch (IOException e) {
        throw new RuntimeException(e);
    }

    // Set up Generative AI inference client with credentials and endpoint
    ClientConfiguration clientConfiguration =
            ClientConfiguration.builder()
                    .readTimeoutMillis(240000)
                    .build();
    GenerativeAiInferenceClient generativeAiInferenceClient =
            GenerativeAiInferenceClient.builder()
                    .configuration(clientConfiguration)
                    .endpoint(ENDPOINT)
                    .build(provider);</code></pre><p>Чтобы сгенерировать ответ на запрос пользователя, чат-бот должен знать, как вызвать модели Generative AI. Для достижения этой цели SDK предлагает представление режима выдачи ответа через класс <code>ServingMode</code>, который можно дополнительно конфигурировать через чат-модель OCI. Для нашего примера я использовал модель <code>meta.llama-3.1-405b-instruct</code> и задал ее вызов через <code>OnDemandServingMode</code>, представляющий режим, при котором модели Generative AI вызываются по требованию, не требуя предварительного деплоймента или постоянного хостинга для модели. </p><pre><code class="java">ServingMode chatServingmode = OnDemandServingMode.builder()
                .modelId("meta.llama-3.1-405b-instruct")
                .build();</code></pre><p>После этого мы можем подготовить <code>ChatRequest</code>, отправить его в LLM модель, используя экземпляр класса <code>GenerativeAiInferenceClient</code>, созданный приведенным выше кодом, и затем получить от него сгенерированный ответ. </p><pre><code class="java">// Send the given prompt to the LLM to generate a response.
public ChatResponse generateResponse(String prompt) {
    // create ChatContent and UserMessage using the given prompt string
    ChatContent content = TextContent.builder()
            .text(prompt)
            .build();
    List&lt;ChatContent&gt; contents = List.of(content);

    Message message = UserMessage.builder()
            .content(contents)
            .build();
    // put the message into a List
    List&lt;Message&gt; messages = List.of(message);

    // create a GenericChatRequest including the current message, and the
    // parameters for the LLM model
    GenericChatRequest genericChatRequest = GenericChatRequest.builder()
            .messages(messages)
            .maxTokens(1000)
            .numGenerations(1)
            .frequencyPenalty(0.0)
            .topP(1.0)
            .topK(1)
            .temperature(0.75)
            .isStream(false)
            .build();

    // create ChatDetails and ChatRequest providing it with the compartment ID
    // and the parameters for the LLM model
   ChatDetails details = ChatDetails.builder()
            .chatRequest(genericChatRequest)
            .compartmentId(OCIGenAIEnv.getCompartmentID())
            .servingMode(chatServingMode)
            .build();
   ChatRequest request = ChatRequest.builder()
            .chatDetails(details)
            .build();

   // send chat request to the AI inference client
   return generativeAiInferenceClient.chat(request);
}</code></pre><p>Текст ответа включает в объект <code>ChatResponse</code>, возвращаемый методом <a href="http://generativeAiInferenceClient.chat"><code>generativeAiInferenceClient.chat</code></a><code>()</code>. Чтобы извлечь текст из <code>ChatResponse</code>, вы можете попробовать воспользоваться приведенным ниже фрагментом кода. </p><pre><code class="java">public String extractResponseText(ChatResponse chatResponse) {
    // get BaseChatResponse from ChatResponse
    BaseChatResponse bcr = chatResponse
            .getChatResult()
            .getChatResponse();
    // extract text from the GenericChatResponse response type
    // GenericChatResponse represents response from llama models
    if (bcr instanceof GenericChatResponse resp) {
        List&lt;ChatChoice&gt; choices = resp.getChoices();
        List&lt;ChatContent&gt; contents = choices.get(choices.size() - 1)
                .getMessage()
                .getContent();
        ChatContent content = contents.get(contents.size() - 1);
        if (content instanceof TextContent textContent) {
            return textContent.getText();
        }
    }
    throw new RuntimeException("Unexpected ChatResponse");
}</code></pre><p>Теперь давайте вызовем приведенные выше методы с промптом, содержащим вопрос об утечках памяти в Java. </p><pre><code class="java">String prompt = "How do I troubleshoot memory leaks?";
ChatResponse response = generateResponse(prompt);
System.out.println(extractResponseText(response));</code></pre><p>Для валидации нашей работы нам необходимо, чтобы ассистент был поднят и работал:</p><ol><li><p>Воспользуйтесь возможностями вашей IDE для управления циклом жизни проекта на Maven или быстро запустите команду <code>mvn verify</code> в окне терминала. Это действие создаст файл <code>troubleshoot-assist-1.0.0.jar</code> внутри каталога target.</p></li><li><p>Запустите приложение с помощью команды <code>mvn exec:java -Dexec.mainClass=JavaTroubleshootingAssistant</code>.</p></li></ol><p>Наш чат-бот пришлет следующий ответ:</p><details class="spoiler"><summary>Много кода</summary><div class="spoiler__content"><pre><code>The age-old problem of memory leaks! Troubleshooting memory leaks can be a challenging and time-consuming process, but with the right tools and techniques, you can identify and fix them. Here's a step-by-step guide to help you troubleshoot memory leaks:

**Preparation**

1. **Understand the symptoms**: Identify the symptoms of the memory leak, such as:
	* Increasing memory usage over time
	* Performance degradation
	* Crashes or errors due to out-of-memory conditions
2. **Gather information**: Collect relevant data about the system, application, and environment, including:
	* Operating system and version
	* Application version and architecture (32-bit or 64-bit)
	* Memory configuration (RAM, virtual memory, and paging file settings)
3. **Choose the right tools**: Select the tools you'll use to troubleshoot the memory leak, such as:
	* Memory profiling tools (e.g., Visual Studio, Valgrind, or AddressSanitizer)
	* System monitoring tools (e.g., Task Manager, Performance Monitor, or top)
	* Debugging tools (e.g., gdb, WinDbg, or Visual Studio Debugger)

**Step 1: Monitor System Resources**

1. **Track memory usage**: Use system monitoring tools to track memory usage over time, including:
	* Total memory usage
	* Memory usage by process or application
	* Memory allocation and deallocation patterns
2. **Identify memory-intensive processes**: Determine which processes or applications are consuming the most memory.

**Step 2: Analyze Memory Allocations**

1. **Use memory profiling tools**: Run memory profiling tools to analyze memory allocations and identify potential leaks.
2. **Collect memory dumps**: Collect memory dumps or snapshots to analyze memory allocation patterns.
3. **Analyze memory allocation patterns**: Look for patterns of memory allocation and deallocation, such as:
	* Memory allocated but not released
	* Memory allocated repeatedly without being released
	* Large memory allocations

**Step 3: Inspect Code and Data Structures**

1. **Review code**: Inspect the code for potential memory leaks, focusing on areas with high memory allocation and deallocation activity.
2. **Check data structures**: Verify that data structures, such as arrays, lists, or trees, are properly managed and released.
3. **Look for circular references**: Identify potential circular references that could prevent memory from being released.

**Step 4: Debug and Test**

1. **Use debugging tools**: Use debugging tools to step through the code, inspect variables, and identify potential issues.
2. **Test hypotheses**: Test hypotheses about the cause of the memory leak by modifying the code or data structures.
3. **Verify fixes**: Verify that fixes or changes resolve the memory leak.

**Additional Tips**

1. **Test under various conditions**: Test the application under different conditions, such as varying loads, inputs, or environments.
2. **Use automated testing**: Use automated testing tools to simulate user interactions and identify potential memory leaks.
3. **Monitor memory usage regularly**: Regularly monitor memory usage to detect potential memory leaks early.

By following these steps and using the right tools, you'll be well-equipped to troubleshoot and fix memory leaks in your application. Happy debugging!</code></pre><p></p></div></details><p>Поскольку мы не дали модели инструкций, на каком контексте фокусироваться, ответ нельзя считать ориентированным на Java или на отладку проблем с памятью в JVM.</p><p>Что же делать, если мы хотим, чтобы ответы от LLM относились именно к отладке Java и JVM? Мы посмотрим на это в следующем разделе.</p><h3>Расширение функций чат-бота с помощью LangChain4j</h3><p>Мы часто слышим упоминания о том, что большие языковые модели могут галлюцинировать и генерировать неточные или абсурдные ответы, либо такие ответы, которые не имеют отношения к специализированной области, в которой заинтересованы мы. Однако, существует несколько приемов, которые могут повышать точность этих моделей и привязывать их вывод к реальным фактам. <strong>RAG </strong>(<a href="https://en.wikipedia.org/wiki/Retrieval-augmented_generation">Retrieval Augmented Generation</a>) — это один из самых популярных и эффективных таких приемов.</p><p>В этом разделе рассказывается, как повысить привязку ранее разработанного Ассистента по отладке Java (<strong>Java Troubleshooting Assistant)</strong> к контексту, заставив его отвечать на наши вопросы по отладке программ на Java с использованием техники RAG с помощью фреймворка <code>LangChain4j</code>. Ассистент будет генерировать свои ответы на базе документа <a href="https://docs.oracle.com/en/java/javase/23/troubleshoot/troubleshooting-guide.pdf">Java Platform, Standard Edition, Troubleshooting Guide</a>. </p><figure class="full-width"><img alt="Рисунок 3: Ассистент по отладке Java " data-src="https://habrastorage.org/getpro/habr/upload_files/2b8/a29/c44/2b8a29c446d2a72c49e0ea36992740c2.png" height="541" src="https://habrastorage.org/r/w1560/getpro/habr/upload_files/2b8/a29/c44/2b8a29c446d2a72c49e0ea36992740c2.png" title="Рисунок 3: Ассистент по отладке Java " width="891"/><div><figcaption>Рисунок 3: Ассистент по отладке Java </figcaption></div></figure><p>Начнем с включения следующих зависимостей для <code>LangChain4j</code> в файл <code>pom.xml</code> проекта. </p><pre><code class="xml">	&lt;dependency&gt;
    		&lt;groupId&gt;dev.langchain4j&lt;/groupId&gt;
    		&lt;artifactId&gt;langchain4j&lt;/artifactId&gt;
    		&lt;version&gt;0.36.2&lt;/version&gt;
	&lt;/dependency&gt;
	&lt;dependency&gt;
    		&lt;groupId&gt;dev.langchain4j&lt;/groupId&gt;
&lt;artifactId&gt;langchain4j-document-parser-apache-pdfbox&lt;/artifactId&gt;
    		&lt;version&gt;0.36.2&lt;/version&gt;
	&lt;/dependency&gt;
	&lt;dependency&gt;
    		&lt;groupId&gt;dev.langchain4j&lt;/groupId&gt;
    		&lt;artifactId&gt;langchain4j-chroma&lt;/artifactId&gt;
    		&lt;version&gt;0.36.2&lt;/version&gt;
	&lt;/dependency&gt;</code></pre><p>Чтобы еще больше усовершенствовать ассистент, мы создадим эмбеддинги для нашего документа, сохраним их в базе данных векторных представлений, добавим возможность извлекать контекст из базы данных для промптов и дополним промпты контекстом. Дополнительно, мы добавим память чата, чтобы он запоминал историю сообщений в нашей беседе. </p><p><strong>1. Создаем эмбеддинги с использованием модели эмбеддингов </strong></p><p>Первым шагом станет создание базы знаний по информации, доступной в гайде по отладке (например,<a href="https://docs.oracle.com/en/java/javase/23/troubleshoot/troubleshooting-guide.pdf">Java Troubleshooting Guide</a>). Для этого необходимо загрузить документ как файл pdf, извлечь из него текст и разбить его на чанки приемлемого размера:</p><ul><li><p><a href="https://docs.langchain4j.dev/tutorials/rag/#document-loader">FileSystemDocumentLoader</a> из модуля <code>LangChain4j</code> может помочь загрузить pdf файлы,</p></li><li><p><a href="https://docs.langchain4j.dev/tutorials/rag/#document-parser">ApachePdfBoxDocumentParser</a> может извлечь из них текст.</p></li><li><p><a href="https://docs.langchain4j.dev/tutorials/rag/#document-splitter">DocumentSplitter</a> может разбить загруженные документы на чанки TextSegment, которые мы передадим модели эмбеддингов для генерации эмбеддингов, как  показано ниже.</p></li></ul><pre><code class="java">DocumentSplitter documentSplitter = DocumentSplitters.recursive(
                800,    // Maximum chunk size in tokens
                40,     // Overlap between chunks
                null    // Default separator
);
public List&lt;TextSegment&gt; chunkPDFFiles(String filePath) {
    List&lt;Document&gt; documents = null;
    try {
        // Load all *.pdf documents from the given directory
        PathMatcher pathMatcher = FileSystems.getDefault().getPathMatcher("glob:*.pdf");
        documents = FileSystemDocumentLoader.loadDocuments(
                filePath,
                pathMatcher,
                new ApachePdfBoxDocumentParser());
    } catch (Exception e) {
        e.printStackTrace();
    }
    // Split documents into TextSegments and add them to a List
    return documents.stream().flatMap(d -&gt; documentSplitter.split(d).stream()).toList();
}</code></pre><p>Теперь мы должны сконвертировать текст из наших документов базы знаний в <strong>эмбеддинги</strong>, которые по сути являются векторами из чисел с плавающей точкой, представляющими текст в цифровом формате.  </p><figure class="full-width"><img alt="Рисунок 4: Эмбеддинги и хранилище векторных представлений " data-src="https://habrastorage.org/getpro/habr/upload_files/c3f/052/99a/c3f05299a7d168e417c15aeebb9b7eff.png" height="591" src="https://habrastorage.org/r/w1560/getpro/habr/upload_files/c3f/052/99a/c3f05299a7d168e417c15aeebb9b7eff.png" title="Рисунок 4: Эмбеддинги и хранилище векторных представлений " width="873"/><div><figcaption>Рисунок 4: Эмбеддинги и хранилище векторных представлений </figcaption></div></figure><p>Для создания этих эмбеддингов мы будем использовать модели эмбеддингов <code>cohere.embed-english-v3.0</code>, предоставляемую сервисом OCI Generative AI. </p><figure class="full-width"><img alt="Рисунок 5: Модели эмбеддингов OCI " data-src="https://habrastorage.org/getpro/habr/upload_files/be7/9e9/77e/be79e977e902dc53b5ebd94408e7d970.png" height="370" src="https://habrastorage.org/r/w1560/getpro/habr/upload_files/be7/9e9/77e/be79e977e902dc53b5ebd94408e7d970.png" title="Рисунок 5: Модели эмбеддингов OCI " width="1155"/><div><figcaption>Рисунок 5: Модели эмбеддингов OCI </figcaption></div></figure><p>Затем мы создадим новый <code>ServingMode</code> для использования модели эмбеддингов. </p><pre><code class="java">// Create a ServingMode specifying the embedding model to be used
ServingMode embeddingServingMode = OnDemandServingMode.builder()
            .modelId("cohere.embed-english-v3.0")
            .build();</code></pre><p>После этого мы можем отправить текст в эту модель и получить обратно векторный эмбеддинг в качестве ответа. </p><pre><code class="java">public Embedding embedContent(String content) {
    List&lt;String&gt; inputs = Collections.singletonList(content);
    // Build embed text details and request from the input string
    // use the embedding model as the serving mode
    EmbedTextDetails embedTextDetails = EmbedTextDetails.builder()
            .servingMode(embeddingServingMode)
            .compartmentId(OCIGenAIEnv.getCompartmentID())
            .inputs(inputs)
            .truncate(EmbedTextDetails.Truncate.None)
            .build();
    EmbedTextRequest embedTextRequest = EmbedTextRequest.builder().embedTextDetails(embedTextDetails).build();

    // send embed text request to the AI inference client
    EmbedTextResponse embedTextResponse = generativeAiInferenceClient.embedText(embedTextRequest);

    // extract embeddings from the embed text response
    List&lt;Float&gt; embeddings = embedTextResponse.getEmbedTextResult().getEmbeddings().get(0);
    // put the embeddings in a float[]
    int len = embeddings.size();
    float[] embeddingsVector = new float[len];
    for (int i = 0; i &lt; len; i++) {
        embeddingsVector[i] = embeddings.get(i);
    }
    // return Embedding of LangChain4j that wraps a float[]
    return new Embedding(embeddingsVector);
}

public List&lt;Embedding&gt; createEmbeddings(List&lt;TextSegment&gt; segments) {
    return segments.stream().map(s -&gt; embModel.embedContent(s.text())).toList();
}</code></pre><p><strong>2. Хранилище эмбеддингов</strong> </p><p>Как только мы создали эмбеддинги для нашего документа, они должны сохраняться в базу данных, которую часто называют хранилищем эмбеддингов или хранилищем векторных представлений. Для нашего примера мы будет использовать хранилище эмбеддингов ChromaDB, однако следует отметить, что <code>LangChain4j</code> поддерживает широкий диапазон <a href="https://docs.langchain4j.dev/tutorials/embedding-stores">хранилищ эмбеддингов</a>.</p><p>Для начала воспользуемся docker для извлечения docker образа <code>chromadb</code>, затем запустим образ, чтобы контейнер <code>chromadb</code> появился на заданном нами порту.</p><pre><code class="bash">docker pull chromadb/chroma
docker run -p 8000:8000 chromadb/chroma</code></pre><p>Теперь, когда у нас есть база данных для векторных представлений, которая работает и слушает по адресу <code>http://localhost:8000</code>, мы можем сохранять в ней эмбеддинги нашего документа. Давайте создадим экземпляр <code>EmbeddingStore</code>, имеющий доступ к этому хранилищу.  </p><pre><code class="java">ChromaEmbeddingStore embeddingStore = ChromaEmbeddingStore.builder()
                .baseUrl("http://localhost:8000")
                .collectionName("Java-collection")
                .build();</code></pre><p>Далее вызовем <code>embeddingStore.addAll()</code>, чтобы добавить сгенерированные эмбеддинги к хранилищу. </p><pre><code class="java">public void storeEmbeddings(List&lt;Embedding&gt; embeddings, List&lt;TextSegment&gt; segments) {
    embeddingStore.addAll(embeddings, segments);
}</code></pre><p>Ну и наконец соберем все части вместе: разделим pdf файл на чанки, создадим эмбеддинги и сохраним их в хранилище векторных представлений. </p><pre><code class="java">public void createVectorStore(String filePath) {
    List&lt;TextSegment&gt; segments = chunkPDFFiles(filePath);
    List&lt;Embedding&gt; embeddings = createEmbeddings(segments);
    storeEmbeddings(embeddings, segments);
}</code></pre><p><strong>3. Извлечение и дополнение промптов</strong></p><p>В этом разделе объясняется, как получить релевантные ответы на вопросы пользователя посредством извлечения информации из хранилища и дополнения промптов извлеченным контекстом, прежде чем отправлять их в LLM для генерации ответа.</p><figure class="full-width"><img alt="Рисунок 6: Имплементация RAG с помощью LangChain4j " data-src="https://habrastorage.org/getpro/habr/upload_files/2db/d40/dcc/2dbd40dcce6bc650aea492fd86ba9e58.png" height="775" src="https://habrastorage.org/r/w1560/getpro/habr/upload_files/2db/d40/dcc/2dbd40dcce6bc650aea492fd86ba9e58.png" title="Рисунок 6: Имплементация RAG с помощью LangChain4j " width="814"/><div><figcaption>Рисунок 6: Имплементация RAG с помощью LangChain4j </figcaption></div></figure><p>Давайте используем тот же вопрос, который мы задавали в предыдущем разделе: </p><pre><code>String question = "How do I troubleshoot memory leaks?";</code></pre><p>Чтобы извлечь контекст, относящийся к этому вопросу, из базы знаний, необходимо провести семантический поиск в хранилище векторных представлений. Для этого мы сначала конвертируем строку в эмбеддинги, используя метод <code>embedContent()</code>, который написали ранее. </p><pre><code class="java">Embedding queryEmbedding = embedContent(question);</code></pre><p>Затем мы осуществляем поиск похожих фрагментов текста, чтобы извлечь их из базы знаний и связать вместе. С помощью <code>PromptTemplate</code> мы комбинируем оригинальный вопрос и извлеченный контекст, чтобы сконструировать новый промпт.  </p><pre><code class="java">    // Find relevant embeddings in embedding store by semantic similarity
    int maxResults = 10;
    double minScore = 0.7;
    List&lt;EmbeddingMatch&lt;TextSegment&gt;&gt; relevantEmbeddings
            = embeddingStore.findRelevant(queryEmbedding, maxResults, minScore);
    String context = relevantEmbeddings.stream()
            .map(match -&gt; match.embedded().text())
            .collect(joining("\n\n"));

    PromptTemplate template = PromptTemplate.from("""
                You are a Java Troubleshooting Assistant. Answer the question in the context of Java or HotSpot JVM.
                Always ask if the user would like to know more about the topic. Do not add signature at the end of the answer.
                Use only the following pieces of context to answer the question at the end.

                Context: 

                Question: 

                Helpful Answer:
                """);
    // add the question and the retrieved context to the prompt template
    Map&lt;String, Object&gt; variables = Map.of(
            "question", question,
            "context", context
    );
    Prompt prompt = template.apply(variables);</code></pre><p>Мы отправим этот дополненный промпт в LLM и получим ответ, содержащий информацию из гайда по отладке. </p><pre><code class="java">    String query = prompt.text();
    response = chatModel.generateResponse(query);
    System.out.println(extractText(response));</code></pre><p>Ниже приводится пример ответа, который использует дополненный промпт: </p><pre><code>To troubleshoot memory leaks in Java applications, you can follow these steps:

1. **Enable Options and Flags for JVM Troubleshooting**: Update the Java Runtime and enable options and flags for JVM troubleshooting to collect useful data.
2. **Gather Relevant Data**: Collect diagnostic data such as heap histograms, garbage collection logs, and Java Flight Recordings to analyze memory usage.
3. **Analyze Heap Histograms**: Examine heap histograms to quickly narrow down memory leaks.
4. **Use Heap Dump Analysis Tools**: Utilize tools like Eclipse Memory Analyzer Tool (MAT) or YourKit to analyze heap dumps.
5. **Analyze Java Flight Recordings**: Use JDK Mission Control (JMC) to analyze Java Flight Recordings and identify leaking objects.
6. **Monitor Memory Usage**: Use JConsole and JDK Mission Control to monitor memory usage and live sets.
7. **Detect Native Memory Leaks**: Use Native Memory Tracking (NMT) to detect native memory leaks.

Additionally, you can use tools like JConsole, JDK Mission Control, and native tools like pmap or PerfMon to monitor memory usage and detect memory leaks.

Would you like to know more about troubleshooting memory leaks or any specific topic mentioned above?</code></pre><p>Ух ты! Этот ответ действительно помогает отлаживать утечки памяти в Java и является довольно точным!</p><p>В последнем предложении выведенного ответа нас спрашивают, хотим ли мы узнать больше по любой из тем, перечисленных в ответе. Чтобы ответить на уточняющий вопрос, модели необходимо получить доступ к ранее заданным вопросам и соответствующим ответам. Давайте посмотрим на то, как добиться этого путем добавления <strong>памяти чата</strong>.</p><p><strong>4. Добавление памяти чата</strong></p><p>Мы хотим, чтобы модель могла получать доступ к ранее заданным вопросам и ответам в рамках беседы, чтобы мы могли задавать уточняющие вопросы. Внедрение такой функциональности становится возможным, если сохранять предшествующую цепочку вопросов и ответов в памяти чата. <code>LangChain4j</code> предлагает несколько реализаций <a href="https://docs.langchain4j.dev/tutorials/chat-memory">ChatMemory</a>, которые можно использовать для запоминания бесед. OCI Generative AI также предоставляет механизм сохранения истории сообщений беседы, и мы воспользуемся им как примером. Как показано ниже, мы сохраним ответы от чата как список объектов класса <code>ChatChoice</code> и воспользуемся ими в дальнейшем при создании нового запроса к чату. </p><pre><code class="java">List&lt;ChatChoice&gt; chatMemory;

public void saveChatResponse(ChatResponse chatResponse) {
    BaseChatResponse bcr = chatResponse.getChatResult().getChatResponse();
    if (bcr instanceof GenericChatResponse resp) {
        chatMemory = resp.getChoices();
    }
}</code></pre><p>Чат-бот может посылать эти сообщения, сохраненные в памяти чата, в LLM вместе с нашим дополненным промптом из метода <code>generateResponse()</code>. </p><pre><code class="java">public ChatResponse generateResponse(String prompt) {
    ...
    Message message = UserMessage.builder()
            .content(contents)
            .build();

    // messages below holds previous messages from the conversation
    List&lt;Message&gt; messages = chatMemory == null ? new ArrayList&lt;&gt;() :
                        chatMemory.stream()
                        .map(ChatChoice::getMessage)
                        .collect(Collectors.toList());
    // add the current query message to list of history messages.
    messages.add(message);

    GenericChatRequest genericChatRequest = GenericChatRequest.builder()
            .messages(messages)  // holds current message + history
            ...
            ...
    ...
    // send chat request to the AI inference client and receive response
    ChatResponse response = generativeAiInferenceClient.chat(request);
    // save the response to the chat memory
    saveChatResponse(response);</code></pre><p>Поскольку мы модифицировали проект, давайте почистим и пересоберем его командой <code>mvn clean verify</code>. Эта команда генерирует новый файл <code>troubleshoot-assist-1.0.0.jar</code> в каталоге <code>target</code>. Теперь запустим приложения, используя команду <code>mvn exec:java -Dexec.mainClass=JavaTroubleshootingAssistant</code>. </p><p>Поскольку у нас подключена память чата, мы можем задать уточняющий вопрос к предыдущему ответу. </p><pre><code>question = "How do I enable NMT?"</code></pre><p>Приведенный ниже вывод показывает, что ответ дает правильную инструкцию по включению Native Memory Tracking (NMT) для отладки проблем с нативной памятью. </p><pre><code>To enable Native Memory Tracking (NMT) in the HotSpot JVM, you can use the following command-line option:

`-XX:NativeMemoryTracking=[off|summary|detail]`

You can set the level of detail to either `summary` or `detail`, depending on the level of information you need. The `summary` level provides a high-level overview of native memory usage, while the `detail` level provides a more detailed breakdown of native memory usage.

For example, to enable NMT with the `summary` level, you can use the following command:

`java -XX:NativeMemoryTracking=summary -jar your_java_app.jar`

You can also enable NMT at runtime using the `jcmd` command:

`jcmd &lt;pid&gt; VM.native_memory summary`

Replace `&lt;pid&gt;` with the process ID of the Java process you want to enable NMT for.

Would you like to know more about using NMT to troubleshoot native memory leaks or how to interpret the NMT output?</code></pre><p>И таким образом у нас появляется свой простой ассистент по отладке Java!</p><p>Полный код примера, который мы разобрали в статье, можно найти здесь: <a href="https://github.com/poonamparhar/Java-Gen-AI">Java-Gen-AI</a>.</p><h3>Заключение</h3><p>В этой статье мы рассмотрели несколько фреймворков и библиотек, которые вносят огромный вклад в расширение экосистемы Java с целью поддержки интеграции ИИ. Фреймворки LangChain4j, Spring AI и Jlama упрощают интеграцию больших языковых моделей в существующие и новые приложения на Java, позволяя разработчикам собирать сложные сценарии работы с ИИ. Более того, облачные сервисы generative AI, такие как <code>Oracle Generative AI</code>, могут масштабироваться и дальше, достигая уровня Enterprise для решений, использующих ИИ. Эти разработки ставят язык и платформу Java на позиции ключевых игроков в основанном на ИИ решениях будущем Enterprise технологий.</p><figure class="full-width"><img data-src="https://habrastorage.org/getpro/habr/upload_files/c16/4b2/4fe/c164b24fe67857325369e7d0e25ab10e.png" height="520" src="https://habrastorage.org/r/w1560/getpro/habr/upload_files/c16/4b2/4fe/c164b24fe67857325369e7d0e25ab10e.png" width="1600"/></figure><p><a href="https://www.springnow.ru">Регистрируйтесь</a> на главную конференцию про Spring на русском языке от сообщества Spring АйО! В мероприятии примут участие не только наши эксперты, но и приглашенные лидеры индустрии.</p></div></div></div><!-- --><!-- --></div><!-- --><!-- --></div><!--]--><!-- --><div class="tm-article-presenter__meta" data-test-id="article-meta-links"><div class="tm-separated-list tm-article-presenter__meta-list"><span class="tm-separated-list__title">Теги:</span><ul class="tm-separated-list__list"><!--[--><li class="tm-separated-list__item"><!--[--><a class="tm-tags-list__link" href="/ru/search/?target_type=posts&amp;order=relevance&amp;q=[java]"><span>java</span></a><!--]--></li><li class="tm-separated-list__item"><!--[--><a class="tm-tags-list__link" href="/ru/search/?target_type=posts&amp;order=relevance&amp;q=[spring+ai]"><span>spring ai</span></a><!--]--></li><li class="tm-separated-list__item"><!--[--><a class="tm-tags-list__link" href="/ru/search/?target_type=posts&amp;order=relevance&amp;q=[LangChain4J]"><span>LangChain4J</span></a><!--]--></li><li class="tm-separated-list__item"><!--[--><a class="tm-tags-list__link" href="/ru/search/?target_type=posts&amp;order=relevance&amp;q=[Jlama]"><span>Jlama</span></a><!--]--></li><li class="tm-separated-list__item"><!--[--><a class="tm-tags-list__link" href="/ru/search/?target_type=posts&amp;order=relevance&amp;q=[generative+ai]"><span>generative ai</span></a><!--]--></li><li class="tm-separated-list__item"><!--[--><a class="tm-tags-list__link" href="/ru/search/?target_type=posts&amp;order=relevance&amp;q=[oracle]"><span>oracle</span></a><!--]--></li><!--]--><!-- --></ul></div><div class="tm-separated-list tm-article-presenter__meta-list"><span class="tm-separated-list__title">Хабы:</span><ul class="tm-separated-list__list"><!--[--><li class="tm-separated-list__item"><!--[--><a class="tm-hubs-list__link" href="/ru/companies/spring_aio/articles/"><!--[--><span>Блог компании Spring АйО</span><!--]--></a><!--]--></li><li class="tm-separated-list__item"><!--[--><a class="tm-hubs-list__link" href="/ru/hubs/java/"><!--[--><span>Java</span><!--]--></a><!--]--></li><li class="tm-separated-list__item"><!--[--><a class="tm-hubs-list__link" href="/ru/hubs/kotlin/"><!--[--><span>Kotlin</span><!--]--></a><!--]--></li><li class="tm-separated-list__item"><!--[--><a class="tm-hubs-list__link" href="/ru/hubs/programming/"><!--[--><span>Программирование</span><!--]--></a><!--]--></li><!--]--><!-- --></ul></div></div><!-- --><!--]--></article><!--]--></div><!-- --></div><div class="tm-article-sticky-panel" data-test-id="article-sticky-panel" style=""><div class="tm-data-icons tm-data-icons tm-data-icons_space-big tm-article-sticky-panel__icons" data-test-id="article-stats-icons"><div class="tm-article-rating tm-data-icons__item"><div class="tm-votes-lever tm-votes-lever tm-votes-lever_appearance-article tm-article-rating__votes-switcher" title="Всего голосов 8: ↑8 и ↓0"><button class="tm-votes-lever__button" data-test-id="votes-lever-upvote-button" title="Нравится" type="button"><svg class="tm-svg-img tm-votes-lever__icon" height="24" width="24"><title>Нравится</title><use xlink:href="/img/megazord-v28.371b7fa3..svg#counter-vote"></use></svg></button><div class="tm-votes-lever__score tm-votes-lever__score_appearance-article tm-votes-lever__score"><!--[--><span><span class="tm-votes-lever__score-counter tm-votes-lever__score-counter_positive tm-votes-lever__score-counter" data-test-id="votes-score-counter">+9</span></span><!--]--></div><button class="tm-votes-lever__button" data-test-id="votes-lever-downvote-button" title="Не нравится" type="button"><svg class="tm-svg-img tm-votes-lever__icon tm-votes-lever__icon_arrow-down" height="24" width="24"><title>Не нравится</title><use xlink:href="/img/megazord-v28.371b7fa3..svg#counter-vote"></use></svg></button></div><!--teleport start--><!--teleport end--><!-- --></div><!-- --><!-- --><button class="bookmarks-button tm-data-icons__item" title="Добавить в закладки" type="button"><span class="tm-svg-icon__wrapper bookmarks-button__icon"><svg class="tm-svg-img tm-svg-icon" height="24" width="24"><title>Добавить в закладки</title><use xlink:href="/img/megazord-v28.371b7fa3..svg#counter-favorite"></use></svg></span><span class="bookmarks-button__counter" title="Количество пользователей, добавивших публикацию в закладки">35</span></button><div class="tm-sharing tm-data-icons__item" title="Поделиться"><button class="tm-sharing__button" type="button"><svg class="tm-sharing__icon" viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M13.8 13.8V18l7.2-6.6L13.8 5v3.9C5 8.9 3 18.6 3 18.6c2.5-4.4 6-4.8 10.8-4.8z" fill="currentColor"></path></svg></button><!--teleport start--><!--teleport end--></div><div class="tm-article-comments-counter-link tm-data-icons__item" title="Читать комментарии"><a class="tm-article-comments-counter-link__link" data-test-id="counter-comments" href="/ru/companies/spring_aio/articles/883964/comments/"><!--[--><svg class="tm-svg-img tm-article-comments-counter-link__icon" height="24" width="24"><title>Комментарии</title><use xlink:href="/img/megazord-v28.371b7fa3..svg#counter-comments"></use></svg><span class="tm-article-comments-counter-link__value">1</span><!--]--></a><!-- --></div><!--[--><!--[--><!--[--><!-- --><!--]--><!--]--><!--]--><!--teleport start--><!--teleport end--><!-- --></div></div></div><!--[--><!--]--><div class="tm-article-presenter__footer"><!--[--><!--[--><div class="tm-article-blocks"><!-- --><!--[--><section class="tm-block tm-block tm-block_spacing-bottom"><!-- --><!--[--><div class="tm-block__body tm-block__body tm-block__body_variant-balanced"><!--[--><div class="tm-article-author" data-test-id="article-author-info"><!--[--><!--[--><div class="tm-article-author__company"><div class="tm-article-author__company-card"><div class="tm-company-snippet"><a class="tm-company-snippet__logo-link" href="/ru/companies/spring_aio/profile/"><div class="tm-entity-image"><img alt="" class="tm-entity-image__pic" height="40" src="//habrastorage.org/getpro/habr/company/8f1/91a/458/8f191a4584b8fab12d15af23e447a1d5.png" width="40"/></div></a><div class="tm-company-snippet__info"><a class="tm-company-snippet__title" data-test-id="company-title" href="/ru/companies/spring_aio/profile/"><span>Spring АйО</span></a><div class="tm-company-snippet__description">Компания</div></div></div><div class="tm-article-author__buttons"><!-- --><!-- --></div></div><div class="tm-article-author__company-contacts"><!--[--><a class="tm-article-author__contact" href="https://telegram.me/spring_aio" rel="noopener" target="_blank">Telegram</a><a class="tm-article-author__contact" href="https://www.springnow.ru" rel="noopener" target="_blank">Сайт</a><!--]--></div><div class="tm-article-author__separator"></div></div><!--]--><!--]--><div class="tm-user-card tm-user-card tm-user-card_variant-article tm-article-author__user-card" data-async-called="true"><div class="tm-user-card__info-container"><div class="tm-user-card__header"><div class="tm-user-card__header-data"><a class="tm-user-card__userpic tm-user-card__userpic_size-40" href="/ru/users/spring_aio/"><div class="tm-entity-image"><img alt="" class="tm-entity-image__pic" src="//habrastorage.org/getpro/habr/avatars/8e0/5e8/a1c/8e05e8a1c5fd4560f661efb2cb00e77e.png"/></div></a><div class="tm-user-card__meta"><div class="tm-counter-container tm-karma tm-karma" title=" 85 голосов "><div class="tm-counter-container__header"><!--[--><div class="karma-display positive" data-v-7635202e="">45</div><!-- --><!--]--></div><div class="tm-counter-container__footer"><!--[--><div class="tm-karma__text">Карма</div><!--teleport start--><!--teleport end--><!--]--></div></div><div class="tm-counter-container" title="Рейтинг пользователя"><div class="tm-counter-container__header"><!--[--><!--[--><!--]--><div class="tm-votes-lever tm-votes-lever tm-votes-lever_appearance-rating"><!-- --><div class="tm-votes-lever__score tm-votes-lever__score_appearance-rating tm-votes-lever__score_no-margin tm-votes-lever__score"><!--[--><span><span class="tm-votes-lever__score-counter tm-votes-lever__score-counter_rating tm-votes-lever__score-counter" data-test-id="votes-score-counter">105.9</span></span><!--]--></div><!-- --></div><!--]--></div><div class="tm-counter-container__footer"><!--[--><span class="tm-rating__text tm-rating__text">Рейтинг</span><!--]--></div></div></div></div></div><div class="tm-user-card__info tm-user-card__info_variant-article tm-user-card__info"><div class="tm-user-card__title tm-user-card__title_variant-article tm-user-card__title"><span class="tm-user-card__name tm-user-card__name_variant-article tm-user-card__name">Spring АйО</span><a class="tm-user-card__nickname tm-user-card__nickname tm-user-card__nickname_variant-article" href="/ru/users/spring_aio/"> @spring_aio</a><!-- --></div><p class="tm-user-card__short-info tm-user-card__short-info_variant-article tm-user-card__short-info" data-test-id="user-card-speciality">Главный по Spring</p></div></div><div class="tm-user-card__buttons tm-user-card__buttons_variant-article tm-user-card__buttons"><!-- --><div class="tm-user-card__button"><div class="tm-button-follow tm-user-card__button-follow"><!-- --><button class="tm-button-follow__button tm-button-follow__button_big" data-test-id="follow-button" type="button">Подписаться</button></div></div><!-- --><div class="tm-user-card__button tm-user-card__button_write" data-test-id="user-card-conversations"><svg class="tm-svg-img tm-user-card__button-icon" height="16" width="16"><title>Отправить сообщение</title><use xlink:href="/img/megazord-v28.371b7fa3..svg#mail"></use></svg></div><!-- --></div><!-- --></div><!-- --></div><!--]--></div><!--]--><!-- --></section><!-- --><!--[--><!--]--><!--]--><div class="tm-article-blocks__comments"><div class="tm-article-page-comments" id="publication-comments"><div><!--[--><div class="tm-article-comments-counter-link tm-article-comments-counter-button"><a class="tm-article-comments-counter-link__link tm-article-comments-counter-link__link_button-style" data-test-id="counter-comments" href="/ru/companies/spring_aio/articles/883964/comments/"><!--[--><svg class="tm-svg-img tm-article-comments-counter-link__icon tm-article-comments-counter-link__icon_contrasted" height="24" width="24"><title>Комментарии</title><use xlink:href="/img/megazord-v28.371b7fa3..svg#counter-comments"></use></svg><span class="tm-article-comments-counter-link__value tm-article-comments-counter-link__value_contrasted"> Комментарии 1 </span><!--]--></a><!-- --></div><!--]--></div></div></div><!--[--><!--[--><!--]--><section class="tm-block tm-block tm-block_spacing-bottom"><header class="tm-block__header tm-block__header tm-block__header_variant-borderless"><div class="tm-block__header-container"><h2 class="tm-block__title tm-block__title tm-block__title_variant-large">Публикации</h2><!--[--><!--]--></div><!-- --></header><!--[--><div class="tm-block__body tm-block__body tm-block__body_variant-condensed-slim"><!--[--><!--[--><div class="tm-tabs tm-tabs"><div class=""><!--[--><span class="tm-tabs__tab-item"><button class="tm-tabs__tab-link tm-tabs__tab-link_active tm-tabs__tab-link_slim tm-tabs__tab-link">Лучшие за сутки</button></span><span class="tm-tabs__tab-item"><button class="tm-tabs__tab-link tm-tabs__tab-link_slim tm-tabs__tab-link">Похожие</button></span><!--]--></div><!-- --></div><div class="similar-and-daily__tab-view"><div class="placeholder-wrapper"><!-- --><!-- --><!-- --><!-- --><!-- --><!-- --><!-- --><!-- --><!-- --><!-- --><!-- --><!-- --><!-- --><!-- --><!-- --><!-- --><!-- --><!-- --><!-- --><!-- --><!-- --><!-- --><!-- --><div class="tm-placeholder-article-cards"><!--[--><div class="tm-placeholder-article-card"><div class="tm-placeholder__user"><div class="tm-placeholder__user-pic loads"></div><div class="tm-placeholder__user-date loads"></div></div><div class="tm-placeholder-article-card__title"><div class="tm-placeholder__line tm-placeholder-article-card__title-line loads"></div><div class="tm-placeholder__line tm-placeholder-article-card__title-line loads"></div></div><div class="tm-placeholder-article-card__icons tm-placeholder__counters"><!--[--><div class="tm-placeholder-data-icon"><div class="tm-placeholder__icon tm-placeholder__icon_large loads"></div><div class="tm-placeholder__line tm-placeholder__line_icon-text"></div></div><div class="tm-placeholder-data-icon"><div class="tm-placeholder__icon tm-placeholder__icon_large loads"></div><div class="tm-placeholder__line tm-placeholder__line_icon-text"></div></div><div class="tm-placeholder-data-icon"><div class="tm-placeholder__icon tm-placeholder__icon_large loads"></div><div class="tm-placeholder__line tm-placeholder__line_icon-text"></div></div><div class="tm-placeholder-data-icon"><div class="tm-placeholder__icon tm-placeholder__icon_large loads"></div><div class="tm-placeholder__line tm-placeholder__line_icon-text"></div></div><!--]--></div></div><div class="tm-placeholder-article-card"><div class="tm-placeholder__user"><div class="tm-placeholder__user-pic loads"></div><div class="tm-placeholder__user-date loads"></div></div><div class="tm-placeholder-article-card__title"><div class="tm-placeholder__line tm-placeholder-article-card__title-line loads"></div><div class="tm-placeholder__line tm-placeholder-article-card__title-line loads"></div></div><div class="tm-placeholder-article-card__icons tm-placeholder__counters"><!--[--><div class="tm-placeholder-data-icon"><div class="tm-placeholder__icon tm-placeholder__icon_large loads"></div><div class="tm-placeholder__line tm-placeholder__line_icon-text"></div></div><div class="tm-placeholder-data-icon"><div class="tm-placeholder__icon tm-placeholder__icon_large loads"></div><div class="tm-placeholder__line tm-placeholder__line_icon-text"></div></div><div class="tm-placeholder-data-icon"><div class="tm-placeholder__icon tm-placeholder__icon_large loads"></div><div class="tm-placeholder__line tm-placeholder__line_icon-text"></div></div><div class="tm-placeholder-data-icon"><div class="tm-placeholder__icon tm-placeholder__icon_large loads"></div><div class="tm-placeholder__line tm-placeholder__line_icon-text"></div></div><!--]--></div></div><div class="tm-placeholder-article-card"><div class="tm-placeholder__user"><div class="tm-placeholder__user-pic loads"></div><div class="tm-placeholder__user-date loads"></div></div><div class="tm-placeholder-article-card__title"><div class="tm-placeholder__line tm-placeholder-article-card__title-line loads"></div><div class="tm-placeholder__line tm-placeholder-article-card__title-line loads"></div></div><div class="tm-placeholder-article-card__icons tm-placeholder__counters"><!--[--><div class="tm-placeholder-data-icon"><div class="tm-placeholder__icon tm-placeholder__icon_large loads"></div><div class="tm-placeholder__line tm-placeholder__line_icon-text"></div></div><div class="tm-placeholder-data-icon"><div class="tm-placeholder__icon tm-placeholder__icon_large loads"></div><div class="tm-placeholder__line tm-placeholder__line_icon-text"></div></div><div class="tm-placeholder-data-icon"><div class="tm-placeholder__icon tm-placeholder__icon_large loads"></div><div class="tm-placeholder__line tm-placeholder__line_icon-text"></div></div><div class="tm-placeholder-data-icon"><div class="tm-placeholder__icon tm-placeholder__icon_large loads"></div><div class="tm-placeholder__line tm-placeholder__line_icon-text"></div></div><!--]--></div></div><div class="tm-placeholder-article-card"><div class="tm-placeholder__user"><div class="tm-placeholder__user-pic loads"></div><div class="tm-placeholder__user-date loads"></div></div><div class="tm-placeholder-article-card__title"><div class="tm-placeholder__line tm-placeholder-article-card__title-line loads"></div><div class="tm-placeholder__line tm-placeholder-article-card__title-line loads"></div></div><div class="tm-placeholder-article-card__icons tm-placeholder__counters"><!--[--><div class="tm-placeholder-data-icon"><div class="tm-placeholder__icon tm-placeholder__icon_large loads"></div><div class="tm-placeholder__line tm-placeholder__line_icon-text"></div></div><div class="tm-placeholder-data-icon"><div class="tm-placeholder__icon tm-placeholder__icon_large loads"></div><div class="tm-placeholder__line tm-placeholder__line_icon-text"></div></div><div class="tm-placeholder-data-icon"><div class="tm-placeholder__icon tm-placeholder__icon_large loads"></div><div class="tm-placeholder__line tm-placeholder__line_icon-text"></div></div><div class="tm-placeholder-data-icon"><div class="tm-placeholder__icon tm-placeholder__icon_large loads"></div><div class="tm-placeholder__line tm-placeholder__line_icon-text"></div></div><!--]--></div></div><div class="tm-placeholder-article-card"><div class="tm-placeholder__user"><div class="tm-placeholder__user-pic loads"></div><div class="tm-placeholder__user-date loads"></div></div><div class="tm-placeholder-article-card__title"><div class="tm-placeholder__line tm-placeholder-article-card__title-line loads"></div><div class="tm-placeholder__line tm-placeholder-article-card__title-line loads"></div></div><div class="tm-placeholder-article-card__icons tm-placeholder__counters"><!--[--><div class="tm-placeholder-data-icon"><div class="tm-placeholder__icon tm-placeholder__icon_large loads"></div><div class="tm-placeholder__line tm-placeholder__line_icon-text"></div></div><div class="tm-placeholder-data-icon"><div class="tm-placeholder__icon tm-placeholder__icon_large loads"></div><div class="tm-placeholder__line tm-placeholder__line_icon-text"></div></div><div class="tm-placeholder-data-icon"><div class="tm-placeholder__icon tm-placeholder__icon_large loads"></div><div class="tm-placeholder__line tm-placeholder__line_icon-text"></div></div><div class="tm-placeholder-data-icon"><div class="tm-placeholder__icon tm-placeholder__icon_large loads"></div><div class="tm-placeholder__line tm-placeholder__line_icon-text"></div></div><!--]--></div></div><!--]--></div><!-- --><!-- --><!-- --><!-- --><!-- --><!-- --><!-- --><!-- --><!-- --><!-- --><!-- --></div><!-- --></div><!--]--><!--]--></div><!--]--><!-- --></section><!--[--><!--]--><!-- --><!--[--><!--]--><!--]--></div><!--]--><!--]--></div></div><!--]--><!--]--></div></div><div class="tm-page__sidebar"><!--[--><div class="tm-layout-sidebar"><div class="tm-layout-sidebar__placeholder_initial"></div><div class="tm-sexy-sidebar_initial tm-sexy-sidebar" style="margin-top:0px;"><!--[--><!--]--><!-- --><div class="tm-layout-sidebar__placeholder_initial"></div><!--[--><section class="tm-block tm-block tm-block_spacing-bottom"><header class="tm-block__header tm-block__header"><div class="tm-block__header-container"><h2 class="tm-block__title tm-block__title">Информация</h2><!--[--><!--]--></div><!-- --></header><!--[--><div class="tm-block__body tm-block__body"><!--[--><div class="tm-company-basic-info"><dl class="tm-description-list tm-description-list tm-description-list_variant-columns-nowrap"><dt class="tm-description-list__title tm-description-list__title_variant-columns-nowrap tm-description-list__title">Сайт</dt><dd class="tm-description-list__body tm-description-list__body_variant-columns-nowrap tm-description-list__body"><!--[--><a class="tm-company-basic-info__link" href="https://t.me/spring_aio" target="_blank">t.me</a><!--]--></dd></dl><dl class="tm-description-list tm-description-list tm-description-list_variant-columns-nowrap"><dt class="tm-description-list__title tm-description-list__title_variant-columns-nowrap tm-description-list__title">Дата регистрации</dt><dd class="tm-description-list__body tm-description-list__body_variant-columns-nowrap tm-description-list__body"><!--[--><time datetime="2024-05-27T07:08:22.000Z" title="2024-05-27, 10:08">27  мая  2024</time><!--]--></dd></dl><!-- --><dl class="tm-description-list tm-description-list tm-description-list_variant-columns-nowrap"><dt class="tm-description-list__title tm-description-list__title_variant-columns-nowrap tm-description-list__title">Численность</dt><dd class="tm-description-list__body tm-description-list__body_variant-columns-nowrap tm-description-list__body"><!--[-->11–30 человек<!--]--></dd></dl><!-- --><!-- --></div><!--]--></div><!--]--><!-- --></section><div class="tm-company-widgets"><!--[--><!--]--></div><!-- --><!-- --><!--]--><!-- --></div></div><!--]--></div></div><!-- --><!--]--></div></div></main><!-- --></div><div class="tm-footer-menu"><div class="tm-page-width"><!--[--><div class="tm-footer-menu__container"><!--[--><div class="tm-footer-menu__block"><p class="tm-footer-menu__block-title">Ваш аккаунт</p><div class="tm-footer-menu__block-content"><ul class="tm-footer-menu__list"><!--[--><li class="tm-footer-menu__list-item"><a href="/kek/v1/auth/habrahabr/?back=/ru/companies/spring_aio/articles/883964/&amp;hl=ru" rel="nofollow" target="_self">Войти</a></li><li class="tm-footer-menu__list-item"><a href="/kek/v1/auth/habrahabr-register/?back=/ru/companies/spring_aio/articles/883964/&amp;hl=ru" rel="nofollow" target="_self">Регистрация</a></li><!--]--></ul></div></div><div class="tm-footer-menu__block"><p class="tm-footer-menu__block-title">Разделы</p><div class="tm-footer-menu__block-content"><ul class="tm-footer-menu__list"><!--[--><li class="tm-footer-menu__list-item"><a class="footer-menu__item-link" href="/ru/articles/">Статьи</a></li><li class="tm-footer-menu__list-item"><a class="footer-menu__item-link" href="/ru/news/">Новости</a></li><li class="tm-footer-menu__list-item"><a class="footer-menu__item-link" href="/ru/hubs/">Хабы</a></li><li class="tm-footer-menu__list-item"><a class="footer-menu__item-link" href="/ru/companies/">Компании</a></li><li class="tm-footer-menu__list-item"><a class="footer-menu__item-link" href="/ru/users/">Авторы</a></li><li class="tm-footer-menu__list-item"><a class="footer-menu__item-link" href="/ru/sandbox/">Песочница</a></li><!--]--></ul></div></div><div class="tm-footer-menu__block"><p class="tm-footer-menu__block-title">Информация</p><div class="tm-footer-menu__block-content"><ul class="tm-footer-menu__list"><!--[--><li class="tm-footer-menu__list-item"><a class="footer-menu__item-link" href="/ru/docs/help/">Устройство сайта</a></li><li class="tm-footer-menu__list-item"><a class="footer-menu__item-link" href="/ru/docs/authors/codex/">Для авторов</a></li><li class="tm-footer-menu__list-item"><a class="footer-menu__item-link" href="/ru/docs/companies/corpblogs/">Для компаний</a></li><li class="tm-footer-menu__list-item"><a class="footer-menu__item-link" href="/ru/docs/docs/transparency/">Документы</a></li><li class="tm-footer-menu__list-item"><a href="https://account.habr.com/info/agreement/?hl=ru_RU" target="_blank">Соглашение</a></li><li class="tm-footer-menu__list-item"><a href="https://account.habr.com/info/confidential/?hl=ru_RU" target="_blank">Конфиденциальность</a></li><!--]--></ul></div></div><div class="tm-footer-menu__block"><p class="tm-footer-menu__block-title">Услуги</p><div class="tm-footer-menu__block-content"><ul class="tm-footer-menu__list"><!--[--><li class="tm-footer-menu__list-item"><a href="https://company.habr.com/ru/corporate-blogs/" target="_blank">Корпоративный блог</a></li><li class="tm-footer-menu__list-item"><a href="https://company.habr.com/ru/advertising/" target="_blank">Медийная реклама</a></li><li class="tm-footer-menu__list-item"><a href="https://company.habr.com/ru/native-special/" target="_blank">Нативные проекты</a></li><li class="tm-footer-menu__list-item"><a href="https://company.habr.com/ru/education-programs/" target="_blank">Образовательные программы</a></li><li class="tm-footer-menu__list-item"><a href="https://company.habr.com/ru/hello-startup/" target="_blank">Стартапам</a></li><!--]--></ul></div></div><!--]--></div><!--]--></div></div><div class="tm-footer"><div class="tm-page-width"><!--[--><div class="tm-footer__container"><!-- --><div class="tm-footer__social"><!--[--><a class="tm-svg-icon__wrapper tm-social-icons__icon" href="https://www.facebook.com/habrahabr.ru" rel="nofollow noopener noreferrer" target="_blank"><svg class="tm-svg-img tm-svg-icon" height="24" width="24"><title>Facebook</title><use xlink:href="/img/new-social-icons-sprite.svg#social-logo-facebook"></use></svg></a><a class="tm-svg-icon__wrapper tm-social-icons__icon" href="https://twitter.com/habr_com" rel="nofollow noopener noreferrer" target="_blank"><svg class="tm-svg-img tm-svg-icon" height="24" width="24"><title>Twitter</title><use xlink:href="/img/new-social-icons-sprite.svg#social-logo-twitter"></use></svg></a><a class="tm-svg-icon__wrapper tm-social-icons__icon" href="https://vk.com/habr" rel="nofollow noopener noreferrer" target="_blank"><svg class="tm-svg-img tm-svg-icon" height="24" width="24"><title>VK</title><use xlink:href="/img/new-social-icons-sprite.svg#social-logo-vk"></use></svg></a><a class="tm-svg-icon__wrapper tm-social-icons__icon" href="https://telegram.me/habr_com" rel="nofollow noopener noreferrer" target="_blank"><svg class="tm-svg-img tm-svg-icon" height="24" width="24"><title>Telegram</title><use xlink:href="/img/new-social-icons-sprite.svg#social-logo-telegram"></use></svg></a><a class="tm-svg-icon__wrapper tm-social-icons__icon" href="https://www.youtube.com/channel/UCd_sTwKqVrweTt4oAKY5y4w" rel="nofollow noopener noreferrer" target="_blank"><svg class="tm-svg-img tm-svg-icon" height="24" width="24"><title>Youtube</title><use xlink:href="/img/new-social-icons-sprite.svg#social-logo-youtube"></use></svg></a><a class="tm-svg-icon__wrapper tm-social-icons__icon" href="https://dzen.ru/habr" rel="nofollow noopener noreferrer" target="_blank"><svg class="tm-svg-img tm-svg-icon" height="24" width="24"><title>Яндекс Дзен</title><use xlink:href="/img/new-social-icons-sprite.svg#social-logo-dzen"></use></svg></a><!--]--></div><!--teleport start--><!--teleport end--><button class="tm-footer__link"><!-- --> Настройка языка</button><a class="tm-footer__link" href="/ru/feedback/">Техническая поддержка</a><div class="tm-footer-copyright"><span class="tm-copyright"><span class="tm-copyright__years">© 2006–2025, </span><span class="tm-copyright__name"><a class="tm-copyright__link" href="https://company.habr.com/" rel="noopener" target="_blank">Habr</a></span></span></div></div><!--]--></div></div><!-- --><!--]--></div><!-- --></div></div>
<div id="overlays"><!-- --><!--teleport anchor--><!-- --><!--teleport anchor--><!-- --><!--teleport anchor--><!-- --><!--teleport anchor--><!-- --><!--teleport anchor--><!-- --><!--teleport anchor--></div>
</body>
</html>
